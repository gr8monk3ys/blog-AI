# =============================================================================
# Blog AI Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your values
# NEVER commit .env to version control
#
# Configuration is validated at startup. The application will fail fast
# if critical configuration is missing or invalid.
#
# Variables marked [REQUIRED] must be set for the application to start.
# Variables marked [RECOMMENDED] are important for production deployments.
# Variables marked [OPTIONAL] enable additional features when configured.

# =============================================================================
# LLM Provider API Keys
# =============================================================================
# At least ONE of these API keys is [REQUIRED] for content generation

# [REQUIRED*] OpenAI API key for GPT models (primary provider)
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# [OPTIONAL] Anthropic API key for Claude models (alternative provider)
# Get your key from: https://console.anthropic.com/
# ANTHROPIC_API_KEY=your_anthropic_api_key_here

# [OPTIONAL] Google Gemini API key (alternative provider)
# Get your key from: https://makersuite.google.com/app/apikey
# GEMINI_API_KEY=your_gemini_api_key_here

# =============================================================================
# Model Configuration
# =============================================================================
# Override default models for each provider

# [OPTIONAL] OpenAI model to use (default: gpt-4)
# Options: gpt-4, gpt-4-turbo, gpt-4o, gpt-3.5-turbo
# OPENAI_MODEL=gpt-4

# [OPTIONAL] Anthropic model to use (default: claude-3-opus-20240229)
# Options: claude-3-opus-20240229, claude-3-sonnet-20240229, claude-3-haiku-20240307
# ANTHROPIC_MODEL=claude-3-opus-20240229

# [OPTIONAL] Gemini model to use (default: gemini-1.5-flash-latest)
# Options: gemini-1.5-pro, gemini-1.5-flash, gemini-1.5-flash-latest
# GEMINI_MODEL=gemini-1.5-flash-latest

# [OPTIONAL] LLM API request timeout in seconds (default: 60)
# Prevents hanging requests if API is unresponsive
# Increase for longer generation requests, decrease for faster failure
LLM_API_TIMEOUT=60

# =============================================================================
# LLM Rate Limiting
# =============================================================================
# Prevent excessive API calls and manage costs

# [OPTIONAL] Enable rate limiting for LLM API calls (default: true)
LLM_RATE_LIMIT_ENABLED=true

# [OPTIONAL] Maximum LLM API calls per minute (default: 60)
LLM_RATE_LIMIT_PER_MINUTE=60

# [OPTIONAL] Maximum requests to queue when rate limited (default: 100)
LLM_RATE_LIMIT_MAX_QUEUE=100

# [OPTIONAL] Maximum seconds to wait for rate limit (default: 60.0)
LLM_RATE_LIMIT_MAX_WAIT=60.0

# =============================================================================
# Server Configuration
# =============================================================================

# [RECOMMENDED] Environment name affects security defaults
# Options: development, staging, production
# HSTS is auto-enabled in production
ENVIRONMENT=development

# [OPTIONAL] Enable development mode (default: false)
# SECURITY: When true, API key authentication may be bypassed
# NEVER set to true in production
DEV_MODE=false

# [OPTIONAL] Server port for backend API (default: 8000)
# Only used in Docker/production deployments
# BACKEND_PORT=8000

# [OPTIONAL] Uvicorn worker count (default: 1)
# Recommended for production: 2 * CPU cores + 1
# UVICORN_WORKERS=4

# =============================================================================
# CORS Configuration
# =============================================================================

# [RECOMMENDED] Comma-separated list of allowed CORS origins
# In production, use specific domains (e.g., https://yourdomain.com)
# SECURITY: Never use wildcards (*) in production
ALLOWED_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

# =============================================================================
# Rate Limiting (API Endpoints)
# =============================================================================

# [OPTIONAL] Enable rate limiting middleware (default: true)
RATE_LIMIT_ENABLED=true

# [OPTIONAL] General endpoints: requests per minute per IP (default: 60)
RATE_LIMIT_GENERAL=60

# [OPTIONAL] Generation endpoints: requests per minute per IP (default: 10)
# Lower limit for expensive LLM API calls
RATE_LIMIT_GENERATION=10

# =============================================================================
# Security Configuration
# =============================================================================

# [OPTIONAL] Enable HTTPS redirect middleware (default: false)
# SECURITY: Only enable when HTTPS is properly configured with valid certificates
HTTPS_REDIRECT_ENABLED=false

# [OPTIONAL] Enable security middleware stack (default: true)
# Includes headers, request validation, request ID
# Only disable for testing purposes
SECURITY_ENABLED=true

# [OPTIONAL] Enable HSTS header (auto-enabled in production)
# SECURITY_HSTS_ENABLED=true

# [OPTIONAL] HSTS max-age in seconds (default: 31536000 = 1 year)
# SECURITY_HSTS_MAX_AGE=31536000

# [OPTIONAL] Maximum request body size in bytes (default: 10MB = 10485760)
# Prevents denial-of-service via large payloads
SECURITY_MAX_BODY_SIZE=10485760

# [OPTIONAL] Trust incoming X-Request-ID headers from clients/proxies
# SECURITY: Only enable behind trusted reverse proxies
SECURITY_TRUST_REQUEST_ID=false

# [OPTIONAL] Request ID prefix for tracing
SECURITY_REQUEST_ID_PREFIX=blog-ai

# [OPTIONAL] Custom Content-Security-Policy
# If not set, uses a restrictive default policy
# SECURITY_CSP_POLICY=default-src 'self'; script-src 'self'

# =============================================================================
# Database (Supabase)
# =============================================================================
# [RECOMMENDED] Required for persistent storage of user data, brand voice, etc.
# If not configured, falls back to in-memory storage (data lost on restart)

# [OPTIONAL] Supabase project URL
# Get from: https://supabase.com/dashboard/project/_/settings/api
# SUPABASE_URL=https://your-project.supabase.co

# [OPTIONAL] Supabase anon/public key (for client-side operations)
# SUPABASE_KEY=your_supabase_anon_key

# [OPTIONAL] Supabase service role key (for admin/server-side operations)
# SECURITY: This key bypasses Row Level Security - never expose to clients
# SUPABASE_SERVICE_ROLE_KEY=your_supabase_service_role_key

# Legacy alias (deprecated - use SUPABASE_SERVICE_ROLE_KEY instead)
# SUPABASE_SERVICE_KEY=your_supabase_service_key

# =============================================================================
# Payment Processing (Stripe)
# =============================================================================
# [OPTIONAL] Required for subscription billing features
# Get your keys from: https://dashboard.stripe.com/apikeys

# [OPTIONAL] Stripe secret API key
# SECURITY: Never expose this in client-side code
STRIPE_SECRET_KEY=

# [OPTIONAL] Stripe webhook signing secret
# Get from: https://dashboard.stripe.com/webhooks
# Required for secure webhook verification
STRIPE_WEBHOOK_SECRET=

# [OPTIONAL] Stripe Price IDs for subscription tiers
# Create these in the Stripe Dashboard under Products > Prices
# These should be recurring prices (subscriptions), not one-time
STRIPE_PRICE_ID_STARTER=
STRIPE_PRICE_ID_PRO=
STRIPE_PRICE_ID_BUSINESS=

# =============================================================================
# Redis (Optional Caching/Queuing)
# =============================================================================
# [OPTIONAL] Redis connection URL for caching and job queues
# Format: redis://[[username:]password@]host[:port][/database]
# REDIS_URL=redis://localhost:6379/0

# =============================================================================
# Research APIs
# =============================================================================
# [OPTIONAL] Enable web research features for content generation

# SERP API for Google search results
# Get your key from: https://serpapi.com/
# SERP_API_KEY=your_serp_api_key_here

# Tavily API for web research
# Get your key from: https://tavily.com/
# TAVILY_API_KEY=your_tavily_api_key_here

# Metaphor API for neural search
# Get your key from: https://metaphor.systems/
# METAPHOR_API_KEY=your_metaphor_api_key_here

# SEC API for financial filings research
# Get your key from: https://sec-api.io/
# SEC_API_API_KEY=your_sec_api_key_here

# =============================================================================
# Image Generation
# =============================================================================

# [OPTIONAL] Provider for image generation (default: openai)
# Options: openai (uses DALL-E 3), stability (uses Stable Diffusion XL)
IMAGE_PROVIDER=openai

# [OPTIONAL] Stability AI API key (required if using stability provider)
# Get your key from: https://platform.stability.ai/
# STABILITY_API_KEY=your_stability_api_key_here

# =============================================================================
# Logging Configuration
# =============================================================================

# [OPTIONAL] Log level (default: INFO)
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# [OPTIONAL] Force JSON log format in development (default: false)
# JSON format is always used in production (ENVIRONMENT=production)
LOG_FORMAT_JSON=false

# [OPTIONAL] Enable request logging middleware (default: true)
# Logs HTTP requests with timing, status codes, and request IDs
REQUEST_LOGGING_ENABLED=true

# =============================================================================
# Error Tracking (Sentry)
# =============================================================================
# [RECOMMENDED] Error tracking for production deployments
# Get your DSN from: https://sentry.io

# [OPTIONAL] Sentry DSN (leave empty to disable)
SENTRY_DSN=

# [OPTIONAL] Sentry environment name (default: development)
SENTRY_ENVIRONMENT=development

# [OPTIONAL] Transaction/trace sampling rate (0.0 to 1.0, default: 0.1)
# 0.1 = 10% of transactions are sampled for performance monitoring
# Set higher in development, lower in production to control costs
SENTRY_TRACES_SAMPLE_RATE=0.1

# [OPTIONAL] Profile sampling rate (0.0 to 1.0, default: 0.1)
# Profiles are sampled from traced transactions
SENTRY_PROFILES_SAMPLE_RATE=0.1

# [OPTIONAL] Release version for tracking deployments
SENTRY_RELEASE=blog-ai@1.0.0

# [OPTIONAL] Server name for identifying instances
SERVER_NAME=blog-ai-api

# =============================================================================
# Local Storage
# =============================================================================

# [OPTIONAL] Directory for conversation persistence
CONVERSATION_STORAGE_DIR=./data/conversations

# [OPTIONAL] Path for API key storage
# SECURITY: Ensure this file has restricted permissions (chmod 600)
API_KEY_STORAGE_PATH=./data/api_keys.json

# [OPTIONAL] Directory for usage tracking data
USAGE_STORAGE_DIR=./data/usage

# =============================================================================
# Quick Start Configuration
# =============================================================================
#
# Minimal configuration to get started (development):
#   1. Copy this file to .env
#   2. Set OPENAI_API_KEY to your OpenAI API key
#   3. Run: python server.py
#
# Recommended production configuration:
#   1. Set ENVIRONMENT=production
#   2. Configure at least one LLM provider (OPENAI_API_KEY, etc.)
#   3. Configure Supabase for persistent storage
#   4. Configure Stripe for billing (if using subscriptions)
#   5. Configure Sentry for error tracking
#   6. Set ALLOWED_ORIGINS to your production domains
#   7. Enable HTTPS_REDIRECT_ENABLED=true
#
# =============================================================================
