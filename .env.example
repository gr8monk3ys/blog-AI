# =============================================================================
# Blog AI Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your values
# NEVER commit .env to version control

# =============================================================================
# Required API Keys
# =============================================================================
OPENAI_API_KEY=your_openai_api_key_here

# =============================================================================
# Optional API Keys (for additional features)
# =============================================================================
# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# GEMINI_API_KEY=your_gemini_api_key_here
# SERP_API_KEY=your_serp_api_key_here
# SEC_API_API_KEY=your_sec_api_key_here

# =============================================================================
# Model Configuration (optional overrides)
# =============================================================================
# OPENAI_MODEL=gpt-4
# ANTHROPIC_MODEL=claude-3-opus-20240229
# GEMINI_MODEL=gemini-1.5-flash-latest

# =============================================================================
# Server Configuration
# =============================================================================
# SECURITY: DEV_MODE defaults to false - set to true only for local development
# When false, API key authentication is required for all endpoints
DEV_MODE=false

# CORS allowed origins (comma-separated)
ALLOWED_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

# =============================================================================
# Rate Limiting
# =============================================================================
# Enable/disable rate limiting (default: true)
RATE_LIMIT_ENABLED=true

# General endpoints: requests per minute per IP (default: 60)
RATE_LIMIT_GENERAL=60

# Generation endpoints: requests per minute per IP (default: 10)
# Lower limit for expensive LLM API calls
RATE_LIMIT_GENERATION=10

# =============================================================================
# Data Storage
# =============================================================================
# Directory for conversation persistence (default: ./data/conversations)
CONVERSATION_STORAGE_DIR=./data/conversations

# =============================================================================
# Logging
# =============================================================================
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL (default: INFO)
LOG_LEVEL=INFO
